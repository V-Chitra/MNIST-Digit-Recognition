{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random #for random index generation for division of test and training sets\n",
    "from __future__ import division #Division does not turn integers to floating point in Python 2.7, hence importing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
      "\n",
      "[42000 rows x 0 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"chitra/train.csv\")\n",
    "print df[[]].isnull() # no missing data as indicated on kaggle link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head())\n",
    "df = df.values #converting to numpy array from data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADntJREFUeJzt3X+MXXWZx/HP0+l0GoYfbdWytS3WH9W1QLbIOFhwAZeg4A9aXCHUH6kb2REF46/sypLsWpMlIUZFsio62MZqEDFRpIaqkGpS0Vo6rUorXaTbnaVDm6lStBXd0pl59o85ZYcy53tu7z33nts+71dC5t7znHPP47GfOffO957zNXcXgHimVN0AgGoQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQU1t5c6mWZdPV3crdwmE8r96Ws/4Iatl3YbCb2aXSbpNUoekr7r7Lan1p6tb59kljewSQMImX1/zunW/7TezDklflHS5pEWSlpvZonpfD0BrNfKZv1fSTnff5e7PSPqWpKXltAWg2RoJ/1xJuyc8H8qWPYeZ9ZnZgJkNHNahBnYHoEyNhH+yPyo87/pgd+939x537+lUVwO7A1CmRsI/JGn+hOfzJO1prB0ArdJI+DdLWmhmLzWzaZKukbS2nLYANFvdQ33uPmJmN0j6kcaH+la7+29K6wxAUzU0zu/u6yStK6kXAC3E13uBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiqpbfuxuSmzp+XrO/45+fdHe05Hn37l3JrUya94dL/u3DbO5L14f2nJutFxp7Mv3vTX9/+VHLb0Ud+29C+kcaZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpy/BE++b0my/sdXpbe/ZdmdyfoV3enx8DGNJarp3+8/PvvuZH1Kwfbpfae3f+gt6e8gfPjm65P1F6zamKwjjTM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRl7l7/xmaDkg5KGpU04u49qfVPtVl+nl1S9/6q1DHjtNza5T8bTG77wRn/nayPKf3/wX1/zt+3JI16/u/wLU8vSG7bqHO7B5P1Zd1/yK0V/e8uuhfBm959bbLe8ZOtyfqJaJOv1wHfnz5wmTK+5PMGd/99Ca8DoIV42w8E1Wj4XdL9ZrbFzPrKaAhAazT6tv8Cd99jZrMlPWBm/+nuGyaukP1S6JOk6Tqpwd0BKEtDZ35335P93CfpHkm9k6zT7+497t7TqfybOQJorbrDb2bdZnbKkceS3ihpe1mNAWiuRt72ny7pHjM78jrfdPcfltIVgKarO/zuvkvS35TYS3sbyx+THi0Yj75290XJ+qO3npmsz/zZ7mQ9ZWToibq3rcWv5/1tsv7vy16SW/vFv9xW8OoMRjUTRxcIivADQRF+ICjCDwRF+IGgCD8QFLfurtHogQO5tR+cOaNg64PJ6in6RbI+UvDqVSoaSjx4/otya0W3BS+6pBeN4cwPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzo+muuhlO3NrRdN7c25qLo4uEBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOD8a8sQnzk/W183/Qm5trODcUzQ1eddjw8l6O98HoR1w5geCIvxAUIQfCIrwA0ERfiAowg8ERfiBoArH+c1staS3Strn7mdly2ZJulvSAkmDkq5296ea1yaqMnX+vGT9imseTNbHlD+1edH1/P+6/Ypk/cVDjyTrSKvlzP81SZcdtexGSevdfaGk9dlzAMeRwvC7+wZJ+49avFTSmuzxGknLSu4LQJPV+5n/dHffK0nZz9nltQSgFZr+3X4z65PUJ0nTdVKzdwegRvWe+YfNbI4kZT/35a3o7v3u3uPuPZ3qqnN3AMpWb/jXSlqRPV4h6d5y2gHQKoXhN7O7JG2U9CozGzKz90m6RdKlZvaYpEuz5wCOI4Wf+d19eU7pkpJ7QRv64x3TkvVPzf5lsj5Fllvbcih97nnxlYzjNxPf8AOCIvxAUIQfCIrwA0ERfiAowg8Exa27g9v16SXJ+iNn5996W2psmu1/WPOh5JZn6OcFr41GcOYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5z/BHVj+umT9G+9Ij+OnLsk9skbKK3/w/vzapxjHrxJnfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+E0Hv2bmlDZ/5YnLTouvxxwrODxc+fHWyvmjl3tzaSHJLNBtnfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IqnCc38xWS3qrpH3ufla2bKWkf5T0u2y1m9x9XbOajG7k785N1m/+an9urdHr8e/782nJ+mn/dlKyPjL0XwX7R1VqOfN/TdJlkyy/1d0XZ/8RfOA4Uxh+d98gaX8LegHQQo185r/BzB42s9VmNrO0jgC0RL3hv13SyyUtlrRX0mfzVjSzPjMbMLOBwzpU5+4AlK2u8Lv7sLuPuvuYpDsk9SbW7Xf3Hnfv6VRXvX0CKFld4TezOROeXilpezntAGiVWob67pJ0saQXmtmQpE9KutjMFktySYOS8u/PDKAtFYbf3ZdPsnhVE3qJK3E9vpQex5ekc7ryr8kvuh6/6Hr+Wz/2zmR9+uaHknW0L77hBwRF+IGgCD8QFOEHgiL8QFCEHwiKW3e3wPCHzk/Wv/zR/0jWX9uVviw3NZw3PPqX5LZXrvynZH3W9zcm6zh+ceYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5y9DwSW5ReP4qUtypcYuy71u11XJbWff/3iyzjTaJy7O/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8JTj3K79O1hu5Hl9qbJrtexfel973Jk/Wr9t9UbK+4/NnJeun7Ho6v/jQtuS2VeqYkZ6a/NBrXpGsT/3xljLbaQrO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLmnx3nNbL6kr0v6K0ljkvrd/TYzmyXpbkkLJA1Kutrdn0q91qk2y8+zS0pou73suWdRsr619xvJetE02VMauJ6/kW3L2H549FBu7ctPpuczaNRdW3rr3vZjSx5I1vtm7EzWr9r5tmR99F0dubWRoSeS26Zs8vU64PuLvhgiqbYz/4ikj7v7qyW9TtL1ZrZI0o2S1rv7Qknrs+cAjhOF4Xf3ve6+NXt8UNIOSXMlLZW0JlttjaRlzWoSQPmO6TO/mS2QdI6kTZJOd/e90vgvCEmzy24OQPPUHH4zO1nSdyR9xN0PHMN2fWY2YGYDh5X/+Q9Aa9UUfjPr1Hjw73T372aLh81sTlafI2nfZNu6e7+797h7T6e6yugZQAkKw29mJmmVpB3u/rkJpbWSVmSPV0i6t/z2ADRLLUN9r5f0U0nbpGfHdW7S+Of+b0s6Q9Ljkq5y9/2p1zpRh/qK/GVpeshp99vSw2Xdj01L1p9e+Exubfm5DyW3ve4FP0/W53aclKyPKf3vJ3U5ciPbNnvfnZY/FCdJh300WS+aGv3av/9Abs0313+p87EM9RVez+/uD0q5RzFekoETBN/wA4Ii/EBQhB8IivADQRF+ICjCDwRVOM5fpqjj/O3MXpueXnzk5M5k/ckzpyfrB5ekx7sbsWbJqmS9tyv/33bRpci/PJQ+L75747XJ+sz16eMya/XGZL1eZV/SC+AERPiBoAg/EBThB4Ii/EBQhB8IivADQTHOD5xAGOcHUIjwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgioMv5nNN7OfmNkOM/uNmX04W77SzJ4ws19l/725+e0CKMvUGtYZkfRxd99qZqdI2mJmD2S1W939M81rD0CzFIbf3fdK2ps9PmhmOyTNbXZjAJrrmD7zm9kCSedI2pQtusHMHjaz1WY2M2ebPjMbMLOBwzrUULMAylNz+M3sZEnfkfQRdz8g6XZJL5e0WOPvDD472Xbu3u/uPe7e06muEloGUIaawm9mnRoP/p3u/l1Jcvdhdx919zFJd0jqbV6bAMpWy1/7TdIqSTvc/XMTls+ZsNqVkraX3x6AZqnlr/0XSHqPpG1m9qts2U2SlpvZYkkuaVDS+5vSIYCmqOWv/Q9Kmuw+4OvKbwdAq/ANPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDm7q3bmdnvJP3PhEUvlPT7ljVwbNq1t3btS6K3epXZ20vc/UW1rNjS8D9v52YD7t5TWQMJ7dpbu/Yl0Vu9quqNt/1AUIQfCKrq8PdXvP+Udu2tXfuS6K1elfRW6Wd+ANWp+swPoCKVhN/MLjOzR81sp5ndWEUPecxs0My2ZTMPD1Tcy2oz22dm2ycsm2VmD5jZY9nPSadJq6i3tpi5OTGzdKXHrt1mvG75234z65D0W0mXShqStFnScnd/pKWN5DCzQUk97l75mLCZXSjpT5K+7u5nZcs+LWm/u9+S/eKc6e6faJPeVkr6U9UzN2cTysyZOLO0pGWS3qsKj12ir6tVwXGr4szfK2mnu+9y92ckfUvS0gr6aHvuvkHS/qMWL5W0Jnu8RuP/eFoup7e24O573X1r9vigpCMzS1d67BJ9VaKK8M+VtHvC8yG115TfLul+M9tiZn1VNzOJ07Np049Mnz674n6OVjhzcysdNbN02xy7ema8LlsV4Z9s9p92GnK4wN1fI+lySddnb29Rm5pmbm6VSWaWbgv1znhdtirCPyRp/oTn8yTtqaCPSbn7nuznPkn3qP1mHx4+Mklq9nNfxf08q51mbp5sZmm1wbFrpxmvqwj/ZkkLzeylZjZN0jWS1lbQx/OYWXf2hxiZWbekN6r9Zh9eK2lF9niFpHsr7OU52mXm5ryZpVXxsWu3Ga8r+ZJPNpTxeUkdkla7+80tb2ISZvYyjZ/tpfFJTL9ZZW9mdpekizV+1dewpE9K+p6kb0s6Q9Ljkq5y95b/4S2nt4s1/tb12Zmbj3zGbnFvr5f0U0nbJI1li2/S+Ofryo5doq/lquC48Q0/ICi+4QcERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKj/A3r4M4m8MeB8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df[:,1:785] #input\n",
    "y = df[:,[0]]   #output label\n",
    "\n",
    "#Printing example for testing refer to https://matplotlib.org/users/image_tutorial.html\n",
    "example = x[101,]\n",
    "plt.imshow(example.reshape((28,28)))\n",
    "print(y[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max Normalization \n",
    "mean_x = np.mean(x, axis = 0) #taking mean across pixels (single channel here)\n",
    "x = x - mean_x\n",
    "x = x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing into training and test set\n",
    "index = random.sample(range(0,42000),42000)\n",
    "train_x = x[index[0:int(0.8*42000)],]\n",
    "test_x = x[index[int(0.8*42000):42000],]\n",
    "train_y = y[index[0:int(0.8*42000)],]\n",
    "test_y = y[index[int(0.8*42000):42000],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting shape of x to a suitable shape and y to categorical variable for keras operation\n",
    "\n",
    "from tensorflow.python.keras import utils\n",
    "\n",
    "train_y = utils.to_categorical(train_y)\n",
    "test_y = utils.to_categorical(test_y)\n",
    "\n",
    "train_x = np.reshape(train_x, (33600,28,28,1))\n",
    "test_x = np.reshape(test_x,(8400,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model - conv layer 28x28x16, max pool layer 14x14x16, conv2 layer 14x14x32, max pool2 layer 7x7x32, fc layer of 128 nodes and softmax layer of 10 categories\n",
    "#image of architecture - https://www.easy-tensorflow.com/tf-tutorials/convolutional-neural-nets-cnns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 5, strides = (1,1), activation = 'relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPool2D(pool_size = 2, strides = (2,2), padding = 'valid'))\n",
    "model.add(Conv2D(filters = 32, kernel_size = 5, strides = (1,1), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = 2, strides = (2,2), padding = 'valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/7\n",
      "33600/33600 [==============================] - 16s 471us/step - loss: 0.2483 - acc: 0.9290 - val_loss: 0.0919 - val_acc: 0.9708\n",
      "Epoch 2/7\n",
      "33600/33600 [==============================] - 18s 521us/step - loss: 0.0735 - acc: 0.9776 - val_loss: 0.0653 - val_acc: 0.9781\n",
      "Epoch 3/7\n",
      "33600/33600 [==============================] - 14s 419us/step - loss: 0.0508 - acc: 0.9838 - val_loss: 0.0657 - val_acc: 0.9785\n",
      "Epoch 4/7\n",
      "33600/33600 [==============================] - 16s 478us/step - loss: 0.0399 - acc: 0.9874 - val_loss: 0.0496 - val_acc: 0.9835\n",
      "Epoch 5/7\n",
      "33600/33600 [==============================] - 13s 398us/step - loss: 0.0305 - acc: 0.9905 - val_loss: 0.0550 - val_acc: 0.9820\n",
      "Epoch 6/7\n",
      "33600/33600 [==============================] - 13s 392us/step - loss: 0.0256 - acc: 0.9918 - val_loss: 0.0445 - val_acc: 0.9867\n",
      "Epoch 7/7\n",
      "33600/33600 [==============================] - 13s 397us/step - loss: 0.0208 - acc: 0.9936 - val_loss: 0.0440 - val_acc: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13b651f90>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model compilation using adam optimization\n",
    "\n",
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(train_x, train_y, validation_data = (test_x,test_y), epochs =7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 1s 149us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.044030064155175797, 0.9866666666666667]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model evaluated to get test accuracy once again\n",
    "model.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6598776e-11 5.9284821e-10 1.5594809e-05 6.2733811e-06 2.1725366e-08\n",
      " 6.5322567e-11 7.2501558e-12 9.9980885e-01 1.6920122e-04 1.4804133e-09]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13119cb10>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADkpJREFUeJzt3X+MXXWZx/HP02E6/Ym0IlBLtd2mEJG4ZXesCOqWsCCoSTFRQhPZmmUdE2lcViCSZhO62TVhjeLW1cUdpNJmFYtRoCYFIQ1JFZfaabfQQqEUGEpttwNbTAtof8w8+8ecmqHM+d7be8+5547P+5WQe+957jnnyQ2fnnvne875mrsLQDzjqm4AQDUIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoE5p5c7GW5dP0ORW7hII5Q96Q0f8sNXz3qbCb2ZXSFohqUPS9939ttT7J2iyPmSXNrNLAAkbfX3d7234a7+ZdUj6rqQrJZ0nabGZndfo9gC0VjO/+RdI2uXuL7j7EUk/lrSomLYAlK2Z8M+U9PKI13uyZW9hZj1m1mdmfUd1uIndAShSM+Ef7Y8Kb7s+2N173b3b3bs71dXE7gAUqZnw75E0a8TrsyXtba4dAK3STPg3SZpnZnPMbLykayStLaYtAGVreKjP3Y+Z2VJJv9DwUN9Kd3+qsM4AlKqpcX53XydpXUG9AGghTu8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqKZm6TWzfkmHJA1KOubu3UU0BaB8TYU/c4m7v1rAdgC0EF/7gaCaDb9LetjMNptZTxENAWiNZr/2X+zue83sDEmPmNkz7r5h5BuyfxR6JGmCJjW5OwBFaerI7+57s8cBSfdJWjDKe3rdvdvduzvV1czuABSo4fCb2WQzm3r8uaTLJW0vqjEA5Wrma/+Zku4zs+Pb+ZG7P1RIVwBK13D43f0FSX9eYC/ASRn6qwuS9YPvnZBbO3KqJdcd9/HmRq+n3T4lWe94dEtT2y8CQ31AUIQfCIrwA0ERfiAowg8ERfiBoIq4qg8l6zhnbrL+3PKpLerk5HWOP5Zbe2jB95ra9unjfpOsTxo3vqntN2Ntb/pU9u/OO6dFneTjyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHOPwYcefc7kvXPvf/x/Npp6bHwbUfOStb/emL60tb/Opg+B2H/0fzef/Da2278dFLmdA0k639zauOX5b4+9Idk/Z8GPpysP7H0A8m66YmT7qloHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IChz95bt7FSb7h+yS1u2P9S+F4AO/C5Z9plnpNd/7qVkeejNN9PrN6F/TXos/dmPrs6t1RrHv/zGG5L1qWvyz62o0kZfr4N+IH1f8gxHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iqub1/Ga2UtKnJA24+/nZsumS1kiaLalf0tXu/lp5baJRgzufb24Dr/5fMY2MxtLD0Tu//5fJ+q6P9Cbr//7anNzaz3suSa479bH2HMcvUj1H/rslXXHCslskrXf3eZLWZ68BjCE1w+/uGyQdOGHxIkmrsuerJF1VcF8AStbob/4z3X2fJGWPNc4BBdBuSr+Hn5n1SOqRpAlKz18GoHUaPfLvN7MZkpQ95t5J0d173b3b3bs71dXg7gAUrdHwr5W0JHu+RNIDxbQDoFVqht/M7pH035LONbM9ZnadpNskXWZmz0m6LHsNYAyp+Zvf3RfnlLgwH7UlxvJ3/md3ctUXr7wzWV+2f36y/vjNH8ytdT62ObluBJzhBwRF+IGgCD8QFOEHgiL8QFCEHwiKKbrRlI7T0tOH7155dm7txQvTQ3kXbv1Msj79pvSxq/NphvNSOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM86MpL3zlvGT9mQvvyK19tcYlubXG8Qef3pmsI40jPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTg/kvr/+cPJ+va//U6NLXTkVn7xg4uSa54252h603Pyb83drEm/3pWsD7429mek58gPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0HVHOc3s5WSPiVpwN3Pz5Ytl/QFSa9kb1vm7uvKarIVOk5/Z7J+7NxZpe37pU9MTNaPTBssbd8f/MDzyfqTc76drHdaZ8P7fvCmryfrM06Z0vC2JWlg8I3c2kUblibXnbf+903teyyo58h/t6QrRln+LXefn/03poMPRFQz/O6+QdKBFvQCoIWa+c2/1MyeNLOVZjatsI4AtESj4b9D0lxJ8yXtk/TNvDeaWY+Z9ZlZ31EdbnB3AIrWUPjdfb+7D7r7kKQ7JS1IvLfX3bvdvbtTXY32CaBgDYXfzGaMePlpSduLaQdAq9Qz1HePpIWSTjezPZJulbTQzOZLckn9kr5YYo8ASlAz/O6+eJTFd5XQS6U+uSF9D/jrT1vfok7aTePj+JL04tHXc2ubDs9MrnvLI9ck610D+fcKkKTZ9+dfcz/3if9JrjuUrP5p4Aw/ICjCDwRF+IGgCD8QFOEHgiL8QFDcujvz82s/lqx/40v5l91aZ7kDQ+NOSW9/18K7G9722jcmJes3PHRtsv6eB9O9TdxzKLc29OQzyXXnaWOyXkuE4bpmcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY58/45qeS9XOuK3HnZsnyy/+YniZbC/NLD72ZvnvSvy5Lj+PP+wlj7X+qOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM87dAx7T0VIbP3npusv781f+RrD/8Zv7ttb928+eT6065r7lxfIxdHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKia4/xmNkvSaklnafjy7F53X2Fm0yWtkTRbUr+kq909f07kwC755e5kfd30R5P1oz6YrP/LjT25tUkPMI6P0dVz5D8m6UZ3f5+kCyVdb2bnSbpF0np3nydpffYawBhRM/zuvs/dt2TPD0naIWmmpEWSVmVvWyXpqrKaBFC8k/rNb2azJV0gaaOkM919nzT8D4SkM4puDkB56g6/mU2R9FNJN7j7wZNYr8fM+sys76gON9IjgBLUFX4z69Rw8H/o7j/LFu83sxlZfYakgdHWdfded+929+5OpW8mCaB1aobfzEzSXZJ2uPvtI0prJS3Jni+R9EDx7QEoSz2X9F4s6VpJ28xsa7ZsmaTbJN1rZtdJ2i3ps+W02P7+9x8uSta/PG1Fsr77WPrn0N8tXpqsT3zsN8k6MJqa4Xf3X0nKu7H8pcW2A6BVOMMPCIrwA0ERfiAowg8ERfiBoAg/EBS37q7T0EcvyK2tWPq95Lq1Lsm95uabkvWpjz2erAON4MgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzp8ZN3Vqsj739h25tYUTh5Lrvv87X0nWz17z62QdKANHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+zDPfPidZv//d+dfsr33jHcl1Z9/z22T9WLIKlIMjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXOc38xmSVot6SxJQ5J63X2FmS2X9AVJr2RvXebu68pqtGxzV3uy/vF7v5Rb63pwU42tv9RAR0C56jnJ55ikG919i5lNlbTZzB7Jat9y92+U1x6AstQMv7vvk7Qve37IzHZImll2YwDKdVK/+c1stqQLJG3MFi01syfNbKWZTctZp8fM+sys76gON9UsgOLUHX4zmyLpp5JucPeDku6QNFfSfA1/M/jmaOu5e6+7d7t7d6e6CmgZQBHqCr+ZdWo4+D90959Jkrvvd/dBdx+SdKekBeW1CaBoNcNvZibpLkk73P32EctnjHjbpyVtL749AGWp56/9F0u6VtI2M9uaLVsmabGZzZfkkvolfbGUDluk49Et6XqL+gBapZ6/9v9Kko1SGrNj+gA4ww8Ii/ADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxCUuadvWV3ozsxe0VvvY326pFdb1sDJadfe2rUvid4aVWRv73X3d9XzxpaG/207N+tz9+7KGkho197atS+J3hpVVW987QeCIvxAUFWHv7fi/ae0a2/t2pdEb42qpLdKf/MDqE7VR34AFakk/GZ2hZk9a2a7zOyWKnrIY2b9ZrbNzLaaWV/Fvaw0swEz2z5i2XQze8TMnsseR50mraLelpvZb7PPbquZfaKi3maZ2aNmtsPMnjKzv8+WV/rZJfqq5HNr+dd+M+uQtFPSZZL2SNokabG7P93SRnKYWb+kbnevfEzYzD4m6XVJq939/GzZ1yUdcPfbsn84p7n7V9ukt+WSXq965uZsQpkZI2eWlnSVpM+rws8u0dfVquBzq+LIv0DSLnd/wd2PSPqxpEUV9NH23H2DpAMnLF4kaVX2fJWG/+dpuZze2oK773P3LdnzQ5KOzyxd6WeX6KsSVYR/pqSXR7zeo/aa8tslPWxmm82sp+pmRnFmNm368enTz6i4nxPVnLm5lU6YWbptPrtGZrwuWhXhH232n3YacrjY3f9C0pWSrs++3qI+dc3c3CqjzCzdFhqd8bpoVYR/j6RZI16fLWlvBX2Myt33Zo8Dku5T+80+vP/4JKnZ40DF/fxRO83cPNrM0mqDz66dZryuIvybJM0zszlmNl7SNZLWVtDH25jZ5OwPMTKzyZIuV/vNPrxW0pLs+RJJD1TYy1u0y8zNeTNLq+LPrt1mvK7kJJ9sKOPfNDz57Up3/1rLmxiFmf2Zho/20vAkpj+qsjczu0fSQg1f9bVf0q2S7pd0r6T3SNot6bPu3vI/vOX0tlDDX13/OHPz8d/YLe7tI5J+KWmbpKFs8TIN/76u7LNL9LVYFXxunOEHBMUZfkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgvp/H+3tmH34krYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Example prediction using model\n",
    "\n",
    "print model.predict(test_x)[0]\n",
    "print test_y[0,]\n",
    "example = np.reshape(test_x[0],(1,784))\n",
    "example = (example * 255 + mean_x) #removing normalization\n",
    "plt.imshow(np.reshape(example,(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"chitra/test.csv\")\n",
    "print(np.shape(df_test))\n",
    "df_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mx Normalization\n",
    "mean_x = np.mean(df_test, axis = 0) #taking mean across pixels (single channel here)\n",
    "df_test = (df_test - mean_x)\n",
    "df_test = df_test/255  \n",
    "\n",
    "#Reshaping data\n",
    "df_test = np.reshape(df_test, (28000,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_y = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.zeros((28000,2), dtype = 'int')\n",
    "output[:,0] = range(1,28001)\n",
    "output[:,1] = np.argmax(df_test_y, axis = 1)\n",
    "df_output = pd.DataFrame(data = output, columns = ['ImageID', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = df_output.to_csv(r\"chitra/output.csv\",index = None, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
